# Ethiopian Medical Business Data Pipeline & Analytics

## ğŸ“Œ Project Overview
This project builds an end-to-end data pipeline to extract, transform, enrich, and serve data from Ethiopian medical business Telegram channels. It leverages modern data tools to create a clean, analytical data warehouse, enriched with AI insights, and exposed via an API for business intelligence.

---

## ğŸ› ï¸ Technologies Used

- **Data Scraping**: Telegram API (Python)
- **Data Lake**: Local JSON files
- **Database**: PostgreSQL
- **Data Transformation**: dbt
- **Image Analysis**: YOLOv8 (Ultralytics)
- **Analytical API**: FastAPI
- **Orchestration**: Dagster

---

## ğŸ§± About dbt in This Project

[dbt](https://www.getdbt.com/) (data build tool) is used to manage the transformation layer of the pipeline. It enables version-controlled, modular SQL modeling and automated testing.

### Key Features:
- Transforms raw Telegram data into clean, analytics-ready models
- Implements data quality tests (`not_null`, `unique`, `relationships`)
- Generates documentation for models and sources
- Supports reproducible and auditable analytics workflows

Models are organized into:
- `staging`: cleaned and renamed raw data
- `marts`: final analytics tables and fact models

---

## ğŸ“‚ Project Structure

```

.
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/                # GitHub Actions CI/CD workflows
â”œâ”€â”€ dbt/
â”‚   â””â”€â”€ telegram_warehouse/
â”‚       â”œâ”€â”€ models/
â”‚       â”‚   â”œâ”€â”€ marts/
â”‚       â”‚   â”‚   â””â”€â”€ dim_channels.sql
â”‚       â”‚   â”‚   â””â”€â”€ dim_dates.sql
â”‚       â”‚   â”‚   â””â”€â”€ fct_messages.sql
â”‚       â”‚   â”‚   
â”‚       â”‚   â”œâ”€â”€ staging/
â”‚       â”‚   â”‚   â””â”€â”€ schema.yml
â”‚       â”‚   â”‚   â””â”€â”€ stg_telegram_messages.sql
â”‚       â”‚   â”‚   â””â”€â”€ stg_yolo_detections.sql
â”‚       â”‚   â””â”€â”€ fact/
â”‚       â”‚   â”‚   â””â”€â”€ schema.yml
â”‚       â”‚   â”‚   â””â”€â”€ fct_image_detections.sql
â”‚       â”‚   â”œâ”€â”€ sources.yml
â”‚       â””â”€â”€ dbt_project.yml
â”œâ”€â”€ notebook/
â”‚   â””â”€â”€ 1.0-telegram-scraper.ipynb  # Jupyter notebook for initial data exploration
â”‚   â””â”€â”€ 3.0-image-detection.ipynb 
â”œâ”€â”€ script/
â”‚   â”œâ”€â”€ scrape_telegram.py         # Script to scrape data from Telegram
â”‚   â”œâ”€â”€ load_json_to_postgres.py   # Loads scraped JSON data into PostgreSQL
â”‚   â””â”€â”€ detect_objects_yolo.py
â”œâ”€â”€ src/
â”‚   â””â”€â”€ telegram_scraper.py        # TelegramScraper class implementation
â”œâ”€â”€ .gitignore                     # Files and folders to ignore in Git
â”œâ”€â”€ Dockerfile                     # Docker build instructions
â”œâ”€â”€ README.md                      # Project overview and setup instructions
â”œâ”€â”€ docker-compose.yml             # Multi-container setup for services
â””â”€â”€ requirements.txt               # Python dependencies

````

---

## âš™ï¸ Setup & Installation

### Prerequisites

- Python 3.8+
- PostgreSQL
- Telegram API ID & Hash

### Steps

```bash
# 1. Clone the repository
git clone git@github.com:kumsa-Mergia/Telegram-Data-to-API.git
cd Telegram-Data-to-API

# 2. Create and activate a virtual environment
python -m venv venv
source venv/bin/activate          # For Linux/Mac
# .\venv\Scripts\activate         # For Windows

# 3. Install dependencies
pip install -r requirements.txt

# 4. PostgreSQL Setup
#    - Create a database: telegram_db
#    - Create schemas: raw, analytics

# 5. dbt Profile
#    Configure ~/.dbt/profiles.yml to connect dbt to telegram_db
````

```
